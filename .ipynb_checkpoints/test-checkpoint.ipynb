{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d482b65-49d4-4b98-9c3d-9c3c8ab4f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Beta\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from stable_baselines3.common.buffers import RolloutBuffer\n",
    "from stable_baselines3.common.utils    import get_schedule_fn\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "writer = SummaryWriter(\"runs/nca\")\n",
    "window_size = 1024\n",
    "n = 16\n",
    "N = n\n",
    "K = 5\n",
    "\n",
    "class ConvBetaActorCritic(nn.Module):\n",
    "    def __init__(self, K, act_dim=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(act_dim, 32, 3, stride=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=1), nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, act_dim, K, K)\n",
    "            conv_out_dim = self.cnn(dummy).shape[1]\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(conv_out_dim, 256), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.alpha_head = nn.Linear(256, act_dim)\n",
    "        self.beta_head  = nn.Linear(256, act_dim)\n",
    "        self.value_head = nn.Linear(256, 1)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    def forward(self, obs):                 # obs: (B, 4, K, K)\n",
    "        x = self.shared(self.cnn(obs))\n",
    "        alpha = F.softplus(self.alpha_head(x)) + 1.0   # keep >1\n",
    "        beta  = F.softplus(self.beta_head(x))  + 1.0\n",
    "        value = self.value_head(x).squeeze(-1)\n",
    "        return alpha, beta, value\n",
    "\n",
    "    # one-stop helper for rollout collection\n",
    "    def act(self, obs):\n",
    "        alpha, beta, value = self(obs)\n",
    "        dist   = Beta(alpha, beta)\n",
    "        action = dist.rsample()                 # (B, 4)\n",
    "        logp   = dist.log_prob(action).sum(-1)  # sum over 4 dims\n",
    "        entropy= dist.entropy().sum(-1)\n",
    "        return action, logp, value, entropy\n",
    "\n",
    "def get_patches(x, K):\n",
    "    N = x.shape[-1]\n",
    "    padding = K // 2\n",
    "    x_padded = F.pad(x.unsqueeze(0), pad=(padding, padding, padding, padding), mode='circular')\n",
    "    patches = F.unfold(x_padded, kernel_size=K)\n",
    "    B = N * N\n",
    "    patches = patches.squeeze(0).transpose(0, 1).reshape(B, 4, K, K)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def symmetry_reward(img: torch.Tensor):\n",
    "    with torch.no_grad():\n",
    "        _, N, _ = img.shape\n",
    "        flipped_h = torch.flip(img, dims=[2])  # horizontal flip\n",
    "        flipped_v = torch.flip(img, dims=[1])  # vertical flip\n",
    "    \n",
    "        # Reward pixels that match their mirror\n",
    "        reward_h = -((img - flipped_h) ** 2).sum(dim=0)\n",
    "        reward_v = -((img - flipped_v) ** 2).sum(dim=0)\n",
    "\n",
    "    return ((reward_h + reward_v) / 2).flatten()\n",
    "    \n",
    "lr_sched  = get_schedule_fn(1e-4)\n",
    "n_envs = N*N\n",
    "n_steps = 128\n",
    "batch_sz = 1024\n",
    "gamma, gae_lambda, clip_eps = 1, 0.95, 0.2\n",
    "vf_coef, ent_coef = 0.5, 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tensor = torch.rand(4, N, N).to(device).float()\n",
    "policy = ConvBetaActorCritic(K).to(device)\n",
    "\n",
    "optim = Adam(policy.parameters(), lr=lr_sched(1.0))\n",
    "buffer = RolloutBuffer(\n",
    "    buffer_size = n_steps,\n",
    "    observation_space = gym.spaces.Box(low=0, high=1, shape=(4, 5, 5), dtype=np.float32),\n",
    "    action_space = gym.spaces.Box(low=0.0, high=1.0, shape=(4,), dtype=np.float32),\n",
    "    device = device,\n",
    "    gae_lambda = gae_lambda,\n",
    "    gamma = gamma,\n",
    "    n_envs = n_envs,\n",
    ")\n",
    "episode_start = np.ones(n_envs, dtype=bool)\n",
    "counter = 0\n",
    "timestamp = 0\n",
    "total_timestamp = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a151a1-8d07-489c-b01e-33c8cb4d9d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[256, 4, 4, 4]' is invalid for input of size 18496",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[43mget_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m, in \u001b[0;36mget_patches\u001b[0;34m(x, K)\u001b[0m\n\u001b[1;32m     66\u001b[0m patches \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39munfold(x_padded, kernel_size\u001b[38;5;241m=\u001b[39mK)\n\u001b[1;32m     67\u001b[0m B \u001b[38;5;241m=\u001b[39m N \u001b[38;5;241m*\u001b[39m N\n\u001b[0;32m---> 68\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[43mpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[256, 4, 4, 4]' is invalid for input of size 18496"
     ]
    }
   ],
   "source": [
    "patches = get_patches(tensor, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c88567e-2fd4-4d06-933a-4cb06b296758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0990b476-5aa1-4dc4-bd8e-f7f51758152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_id = None\n",
    "\n",
    "def update_tensor():\n",
    "    global tensor, episode_start, timestamp, counter\n",
    "    with torch.no_grad():\n",
    "        patches = get_patches(tensor, K)\n",
    "        actions, logp, values, _ = policy.act(patches)        \n",
    "        y = actions.view(32, 32, 4).permute(2, 0, 1)\n",
    "        rewards = symmetry_reward(y)\n",
    "        tensor = y.clone()\n",
    "\n",
    "    writer.add_scalar(\"Reward\", rewards.cpu().numpy().mean(), timestamp)\n",
    "\n",
    "    buffer.add(\n",
    "        patches.cpu(),\n",
    "        actions.cpu(),\n",
    "        rewards.cpu(),                  \n",
    "        episode_start,\n",
    "        values.cpu(),\n",
    "        logp.cpu(),\n",
    "    )\n",
    "    episode_start = np.zeros(n_envs, dtype=bool)\n",
    "\n",
    "    timestamp += 1\n",
    "    counter += 1\n",
    "    if counter == n_steps:\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            patches = get_patches(tensor, K)\n",
    "            last_values = policy(patches)[-1]\n",
    "            buffer.compute_returns_and_advantage(last_values.detach(), episode_start)\n",
    "\n",
    "        for _ in range(4):\n",
    "            for batch in buffer.get(batch_sz):\n",
    "                obs_b, act_b, old_val_b, old_logp_b, adv_b, ret_b = batch\n",
    "                logits, values = policy(obs_b)\n",
    "                dist   = torch.distributions.Categorical(logits=logits)\n",
    "                logp_b = dist.log_prob(act_b)\n",
    "                entropy_b = dist.entropy()\n",
    "        \n",
    "                ratio = (logp_b - old_logp_b).exp()\n",
    "                pg_loss = -torch.min(ratio * adv_b,\n",
    "                                     torch.clamp(ratio, 1 - clip_eps, 1 + clip_eps) * adv_b).mean()\n",
    "                value_loss = (ret_b - values).pow(2).mean()\n",
    "                entropy_loss = -entropy_b.mean()\n",
    "        \n",
    "                loss = pg_loss + vf_coef * value_loss + ent_coef * entropy_loss\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "        buffer.reset()\n",
    "        episode_start = np.ones(n_envs, dtype=bool)\n",
    "\n",
    "    optim.param_groups[0][\"lr\"] = lr_sched(timestamp / total_timestamp)\n",
    "\n",
    "def tensor_to_texture():\n",
    "    # Convert (4, N, N) -> (N, N, 4) and scale to 0-255\n",
    "    image_tensor = tensor.cpu().numpy()\n",
    "    data = np.transpose(image_tensor, (1, 2, 0)) * 255\n",
    "    data = data.astype(np.uint8)\n",
    "\n",
    "    glBindTexture(GL_TEXTURE_2D, texture_id)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, n, n, 0, GL_RGBA, GL_UNSIGNED_BYTE, data)\n",
    "\n",
    "def display():\n",
    "    glClear(GL_COLOR_BUFFER_BIT)\n",
    "    glLoadIdentity()\n",
    "\n",
    "    tensor_to_texture()\n",
    "\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glBindTexture(GL_TEXTURE_2D, texture_id)\n",
    "\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0, 0); glVertex2f(0, 0)\n",
    "    glTexCoord2f(1, 0); glVertex2f(window_size, 0)\n",
    "    glTexCoord2f(1, 1); glVertex2f(window_size, window_size)\n",
    "    glTexCoord2f(0, 1); glVertex2f(0, window_size)\n",
    "    glEnd()\n",
    "\n",
    "    glDisable(GL_TEXTURE_2D)\n",
    "    glutSwapBuffers()\n",
    "\n",
    "def reshape(w, h):\n",
    "    glViewport(0, 0, w, h)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, window_size, 0, window_size)  # bottom-left origin\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "\n",
    "def timer(value):\n",
    "    update_tensor()\n",
    "    glutPostRedisplay()\n",
    "    glutTimerFunc(100, timer, 0)\n",
    "\n",
    "def mouse_click(button, state, x, y):\n",
    "    global tensor\n",
    "    if button == GLUT_LEFT_BUTTON and state == GLUT_DOWN:\n",
    "        cell_size = window_size // n\n",
    "        grid_x = x // cell_size\n",
    "        grid_y = (window_size - y) // cell_size  # Flip y-axis\n",
    "\n",
    "        if 0 <= grid_x < n and 0 <= grid_y < n:\n",
    "            tensor[:, grid_y, grid_x] = 0  # Set RGBA to 0\n",
    "            #print(f\"Set tensor[:, {grid_y}, {grid_x}] = 0\")\n",
    "            glutPostRedisplay()\n",
    "\n",
    "def init_texture():\n",
    "    global texture_id\n",
    "    texture_id = glGenTextures(1)\n",
    "    glBindTexture(GL_TEXTURE_2D, texture_id)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n",
    "\n",
    "def main():\n",
    "    glutInit()\n",
    "    glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGB)\n",
    "    glutInitWindowSize(window_size, window_size)\n",
    "    glutInitWindowPosition(100, 100)\n",
    "    glutCreateWindow(b\"RGBA Tensor Renderer\")\n",
    "\n",
    "    glClearColor(0.0, 0.0, 0.0, 1.0)\n",
    "    init_texture()\n",
    "\n",
    "    glutDisplayFunc(display)\n",
    "    glutReshapeFunc(reshape)\n",
    "    glutMouseFunc(mouse_click)\n",
    "    glutTimerFunc(0, timer, 0)\n",
    "\n",
    "    glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2fc91-be35-4105-a15a-61159432dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function GLUTTimerCallback.__call__.<locals>.deregister at 0x79acc3181d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andy/anaconda3/envs/ngsf/lib/python3.9/site-packages/OpenGL/GLUT/special.py\", line 164, in deregister\n",
      "    function( value )\n",
      "  File \"/tmp/ipykernel_955957/3215883732.py\", line 93, in timer\n",
      "  File \"/tmp/ipykernel_955957/3215883732.py\", line 36, in update_tensor\n",
      "ValueError: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a4c2f-d254-4251-af69-2942bb6b48b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
